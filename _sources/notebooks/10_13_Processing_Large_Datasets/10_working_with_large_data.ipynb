{"cells": [{"cell_type": "markdown", "id": "413a3048-7624-4fa6-a0e5-a2d92e55f9d0", "metadata": {}, "source": ["# Working With Large Data\n", "**Learning how to work with large experimental datasets using a block scan model and GPU acceleration.**\n", "\n", "All tutorials so far have been using either simulated data (MoonFlower) or experimental data specifically prepared and reduced in memory for the purpose of those tutorials. From now, we are going to look at full-sized data in exactely the format that it has been collected at the various instruments and microscopes. This means we should certainly use GPU-accelerated reconstruction engines and also adopt using the block scan models which are more efficient in dealing with large data. "]}, {"cell_type": "markdown", "id": "f5168c17-80a9-40c7-a69c-77f425d671e2", "metadata": {}, "source": ["## The data\n", "At the I08-1 instrument at the Diamond Light Source, raw data is written into HDF5/Nexus files. As an example, we can look at the original raw data from the nanogold test sample which is stored in ```\"dls_i08_nanogold_spiral/i08-1-5776.nxs\"``` and inspect the relevant entries\n", "```python\n", "import h5py, os\n", "tutorial_data_home = \"../../data/\"\n", "dataset = \"dls_i08_nanogold_spiral/i08-1-5776.nxs\"\n", "path_to_data = os.path.join(tutorial_data_home, dataset)\n", "with h5py.File(path_to_data) as f:\n", "    keys = [\"entry/axis/data\", \"entry/axis/SampleX_value\", \"entry/axis/SampleY_value\"]\n", "    print(\"The file {} has the following relevant entries: \\n\".format(path_to_data))\n", "    print('\\n'.join('\\t* {0:<30} shape = {1:}'.format(k,f[k].shape) for k in keys))\n", "```\n", "for the diffraction intensities and the scan positions\n", "```bash\n", "The file ../../data/dls_i08_nanogold_spiral/i08-1-5776.nxs has the following relevant entries: \n", "\n", "\t* entry/axis/data                shape = (17671, 2048, 2048)\n", "\t* entry/axis/SampleX_value       shape = (17671, 1, 1)\n", "\t* entry/axis/SampleY_value       shape = (17671, 1, 1)\n", "```\n", "\n", "which follow a \"spiral\" trajectory where for each point along the spiral, the X and Y coordinate is saved in ```entry/axis/SampleX_value``` and ```entry/axis/SampleY_value```, respectively\n", "\n", "![](./_assets/i08_nanogold_pos.png)\n"]}, {"cell_type": "markdown", "id": "deb81ce9-0df2-4681-8639-dbffa121e387", "metadata": {}, "source": ["---"]}, {"cell_type": "code", "execution_count": null, "id": "f12c532f-6e99-4855-b11b-507ca27e2264", "metadata": {}, "outputs": [], "source": ["import h5py, os\n", "tutorial_data_home = \"../../data/\"\n", "dataset = \"dls_i08_nanogold_spiral/i08-1-5776.nxs\"\n", "path_to_data = os.path.join(tutorial_data_home, dataset)\n", "with h5py.File(path_to_data) as f:\n", "    keys = [\"entry/axis/data\", \"entry/axis/SampleX_value\", \"entry/axis/SampleY_value\"]\n", "    print(\"The file {} has the following relevant entries: \\n\".format(path_to_data))\n", "    print('\\n'.join('\\t* {0:<30} shape = {1:}'.format(k,f[k].shape) for k in keys))"]}, {"cell_type": "markdown", "id": "dac81d7f-ab27-4283-9c99-756466bd33ec", "metadata": {}, "source": ["## Loading the data\n", "\n", "We use the Hdf5Loader for reading the data into PtyPy with ```orientation=2```\n", "\n", "```python\n", "p.scans.scan_00.data = u.Param()\n", "p.scans.scan_00.data.name = 'Hdf5Loader'\n", "p.scans.scan_00.data.orientation = 2\n", "```\n", "\n", "providing the path and key for the diffraction intensities\n", "\n", "```python\n", "p.scans.scan_00.data.intensities = u.Param()\n", "p.scans.scan_00.data.intensities.file = path_to_data\n", "p.scans.scan_00.data.intensities.key = \"entry/axis/data\"\n", "```\n", "\n", "and the slow/fast axis of the scan positions:\n", "\n", "```python\n", "p.scans.scan_00.data.positions = u.Param()\n", "p.scans.scan_00.data.positions.file = path_to_data\n", "p.scans.scan_00.data.positions.slow_key = \"entry/axis/SampleY_value\"\n", "p.scans.scan_00.data.positions.slow_multiplier = 1e-3\n", "p.scans.scan_00.data.positions.fast_key = \"entry/axis/SampleX_value\"\n", "p.scans.scan_00.data.positions.fast_multiplier = 1e-3\n", "```\n", "\n", "Instead of loading the entire scan which has $17671$ scan points, we can limit ourselves to the first $1000$ positions using ```bounding_box.fast_axis_bounds```:\n", "\n", "```python\n", "p.scans.scan_00.data.positions.bounding_box = u.Param()\n", "p.scans.scan_00.data.positions.bounding_box.fast_axis_bounds = [0,1000]\n", "```\n", "\n", "The raw data collected at I08-1 also needs to be corrected for the dark current, which can be achieved by loading a ```darkfield``` image \n", "\n", "```python\n", "p.scans.scan_00.data.darkfield = u.Param()\n", "p.scans.scan_00.data.darkfield.file = path_to_data\n", "p.scans.scan_00.data.darkfield.key = \"entry/instrument/darkFieldCollector/darkField\"\n", "```\n", "\n", "that will be subtracted from each loaded diffraction pattern inside the Hdf5Loader class. Finally, we need to provide the correct meta information (energy, distance, pixel size)\n", "\n", "```python\n", "p.scans.scan_00.data.energy = 0.710\n", "p.scans.scan_00.data.distance = 0.072\n", "p.scans.scan_00.data.psize = 11e-6\n", "```\n", "\n", "and we can specify a ```shape``` smaller or equal to the original shape of the data (2048x2048) as well as ```rebin=2```\n", "\n", "```python\n", "p.scans.scan_00.data.shape = (1024,1024)\n", "p.scans.scan_00.data.rebin = 2\n", "p.scans.scan_00.data.auto_center = False\n", "p.scans.scan_00.data.center = [1038,1018]\n", "```\n", "\n", "which will crop all diffraction patterns around the provided center at (1038,1018) to a new shape of ```(1024,1024)``` and bin the resulting frames into a final shape of ```(512,512)```. For this particular example, these operations are save to do without loosing any relevant information in the diffraction data."]}, {"cell_type": "markdown", "id": "b7aaf102-5d6f-426c-9e84-35bcf4d5034d", "metadata": {}, "source": ["## The scan model\n", "\n", "For this example, it is best to use the ```\"BlockFull\"``` scan model\n", "\n", "```python\n", "p.scans = u.Param()\n", "p.scans.scan_00 = u.Param()\n", "p.scans.scan_00.name = 'BlockFull'\n", "```\n", "\n", "with a block size defined by ```frames_per_block``` of $100$\n", "\n", "```python\n", "p.frames_per_block = 100\n", "```\n", "\n", "which will load in the data frames in chunks of $100$ and then does all the processing on the GPU over the entire block which provides a boost in performance since compuations within each block can be distributed over many GPU threads."]}, {"cell_type": "markdown", "id": "510f0f7f-09cb-4eff-9c4c-932642da61e5", "metadata": {}, "source": ["## Reconstruction engine\n", "\n", "For the reconstruction we use the difference map (DM) engine the set of paramters most commonly used for the I08-1 instrument\n", "\n", "```python\n", "p.engines = u.Param()\n", "p.engines.engine = u.Param()\n", "p.engines.engine.name = \"DM_pycuda\"\n", "p.engines.engine.numiter = 200\n", "p.engines.engine.numiter_contiguous = 10\n", "p.engines.engine.probe_support = None\n", "p.engines.engine.probe_update_start = 0\n", "p.engines.engine.probe_fourier_support = None\n", "p.engines.engine.record_local_error = False\n", "p.engines.engine.alpha = 0.95\n", "p.engines.engine.fourier_power_bound = 0.25\n", "p.engines.engine.overlap_converge_factor = 0.001\n", "p.engines.engine.overlap_max_iterations = 20\n", "p.engines.engine.update_object_first = False\n", "p.engines.engine.obj_smooth_std = 20\n", "p.engines.engine.object_inertia = 0.001\n", "p.engines.engine.probe_inertia = 0.001\n", "p.engines.engine.clip_object = [0,1]\n", "```\n", "\n", "resulting in a reconstruction of the nanogold sample after $200$ iterations\n", "\n", "![](./_assets/i08_nanogold_recons_dm.png)"]}, {"cell_type": "markdown", "id": "64f75030-3d41-4665-bb27-b66305fd2cf2", "metadata": {}, "source": ["`````{admonition} Exercise \n", ":class: attention\n", "Modify data loading (e.g. <code>rebin</code> or <code>shape</code>) parameters and engine parameters (e.g. <code>fourier_power_bound</code>) and observe if/how it improves the quality, convergence or speed of the reconstruction.\n", "`````"]}, {"cell_type": "markdown", "id": "bc8f7e85-7830-406d-813f-89aae9f47459", "metadata": {}, "source": ["---"]}, {"cell_type": "code", "execution_count": null, "id": "ee3cbe0e-7393-4e07-8e6c-a0063eb55dbe", "metadata": {}, "outputs": [], "source": ["import ptypy, os\n", "import ptypy.utils as u\n", "\n", "# This will import the HDF5Loader class\n", "ptypy.load_ptyscan_module(\"hdf5_loader\")\n", "\n", "# This will import the GPU engines\n", "ptypy.load_gpu_engines(\"cuda\")  \n", "\n", "# Root directory of tutorial data\n", "tutorial_data_home = \"../../data/\"\n", "\n", "# Dataset for this tutorial\n", "dataset = \"dls_i08_nanogold_spiral/i08-1-5776.nxs\"\n", "\n", "# Absolute path to HDF5 file with raw data\n", "path_to_data = os.path.join(tutorial_data_home, dataset)\n", "\n", "# Create parameter tree\n", "p = u.Param()\n", "\n", "# Set verbose level to info\n", "p.verbose_level = \"interactive\"\n", "\n", "# Scan label\n", "p.run = \"dls_i08_nanogold\"\n", "\n", "# Data loading and processing should \n", "# happen in chunks of this size\n", "p.frames_per_block = 100\n", "\n", "# Set io settings (no files saved)\n", "p.io = u.Param()\n", "p.io.rfile = None\n", "p.io.autosave = u.Param(active=False)\n", "p.io.interaction = u.Param(active=False)\n", "\n", "# Live-plotting during the reconstruction\n", "p.io.autoplot = u.Param()\n", "p.io.autoplot.active=True\n", "p.io.autoplot.threaded = False\n", "p.io.autoplot.layout = \"jupyter\"\n", "p.io.autoplot.interval = 10\n", "\n", "# Define the scan model\n", "p.scans = u.Param()\n", "p.scans.scan_00 = u.Param()\n", "p.scans.scan_00.name = 'BlockFull'\n", "\n", "# Initial illumination (based on simulated optics)\n", "p.scans.scan_00.illumination = u.Param()\n", "p.scans.scan_00.illumination.model = None\n", "p.scans.scan_00.illumination.photons = None\n", "p.scans.scan_00.illumination.aperture = u.Param()\n", "p.scans.scan_00.illumination.aperture.form = \"circ\"\n", "p.scans.scan_00.illumination.aperture.size = 333e-6\n", "p.scans.scan_00.illumination.propagation = u.Param()\n", "p.scans.scan_00.illumination.propagation.focussed = 13.725e-3\n", "p.scans.scan_00.illumination.propagation.parallel = 45e-6\n", "p.scans.scan_00.illumination.propagation.antialiasing = 1\n", "p.scans.scan_00.illumination.diversity = u.Param()\n", "p.scans.scan_00.illumination.diversity.power = 0.1\n", "p.scans.scan_00.illumination.diversity.noise = [0.5,1.0]\n", "\n", "# Initial object\n", "p.scans.scan_00.sample = u.Param()\n", "p.scans.scan_00.sample.model = None\n", "p.scans.scan_00.sample.diversity = None\n", "p.scans.scan_00.sample.process = None\n", "\n", "# Coherence parameters (modes)\n", "p.scans.scan_00.coherence = u.Param()\n", "p.scans.scan_00.coherence.num_probe_modes = 1\n", "p.scans.scan_00.coherence.num_object_modes = 1\n", "\n", "# Data loader\n", "p.scans.scan_00.data = u.Param()\n", "p.scans.scan_00.data.name = 'Hdf5Loader'\n", "p.scans.scan_00.data.orientation = 2\n", "\n", "p.scans.scan_00.data.intensities = u.Param()\n", "p.scans.scan_00.data.intensities.file = path_to_data\n", "p.scans.scan_00.data.intensities.key = \"entry/axis/data\"\n", "\n", "p.scans.scan_00.data.positions = u.Param()\n", "p.scans.scan_00.data.positions.file = path_to_data\n", "p.scans.scan_00.data.positions.slow_key = \"entry/axis/SampleY_value\"\n", "p.scans.scan_00.data.positions.slow_multiplier = 1e-3\n", "p.scans.scan_00.data.positions.fast_key = \"entry/axis/SampleX_value\"\n", "p.scans.scan_00.data.positions.fast_multiplier = 1e-3\n", "p.scans.scan_00.data.positions.bounding_box = u.Param()\n", "p.scans.scan_00.data.positions.bounding_box.fast_axis_bounds = [0,1000]\n", "\n", "p.scans.scan_00.data.darkfield = u.Param()\n", "p.scans.scan_00.data.darkfield.file = path_to_data\n", "p.scans.scan_00.data.darkfield.key = \"entry/instrument/darkFieldCollector/darkField\"\n", "\n", "p.scans.scan_00.data.energy = 0.710\n", "p.scans.scan_00.data.distance = 0.072\n", "p.scans.scan_00.data.psize = 11e-6\n", "p.scans.scan_00.data.shape = (1024,1024)\n", "p.scans.scan_00.data.rebin = 2\n", "p.scans.scan_00.data.auto_center = False\n", "p.scans.scan_00.data.center = [1038,1018]\n", "\n", "# Reconstruct using GPU-accelerated DM\n", "p.engines = u.Param()\n", "p.engines.engine = u.Param()\n", "p.engines.engine.name = \"DM_pycuda\"\n", "p.engines.engine.numiter = 200\n", "p.engines.engine.numiter_contiguous = 10\n", "p.engines.engine.probe_support = None\n", "p.engines.engine.probe_update_start = 0\n", "p.engines.engine.probe_fourier_support = None\n", "p.engines.engine.record_local_error = False\n", "p.engines.engine.alpha = 0.95\n", "p.engines.engine.fourier_power_bound = 0.25\n", "p.engines.engine.overlap_converge_factor = 0.001\n", "p.engines.engine.overlap_max_iterations = 20\n", "p.engines.engine.update_object_first = False\n", "p.engines.engine.obj_smooth_std = 20\n", "p.engines.engine.object_inertia = 0.001\n", "p.engines.engine.probe_inertia = 0.001\n", "p.engines.engine.clip_object = [0,1]\n", "\n", "# Run reconstruction\n", "P = ptypy.core.Ptycho(p,level=5)"]}], "metadata": {"kernelspec": {"display_name": "PtyPy", "language": "python", "name": "ptypy_pycuda"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.15"}}, "nbformat": 4, "nbformat_minor": 5}