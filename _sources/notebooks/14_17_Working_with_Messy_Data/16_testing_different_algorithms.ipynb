{"cells": [{"cell_type": "markdown", "id": "413a3048-7624-4fa6-a0e5-a2d92e55f9d0", "metadata": {}, "source": ["# Testing different algorithms\n", "**Exploring different reconstruction algorithms and finding the one best suited for a particular dataset.**\n", "\n", "Every experimental dataset is different and sometimes the common choice of DM or ePIE as an engine for the initial reconstruction might not be the best solution. Ptychography is a very popular technique with lots of new algorithms and modifications to existing algorithms published every year. It might be worth exploring some of these new methods when working with a challenging experimental data set. In this example, we are looking at an algorithm called the [semi-implicit relaxed Douglas-Rachford](https://doi.org/10.1364/OE.27.031246) (SDR) algorithm, which is essentialy a variation of ePIE with a DM-like Fourier update. "]}, {"cell_type": "markdown", "id": "e0ea6405-a823-47b7-b42f-2219032d3158", "metadata": {}, "source": ["## The data\n", "**Thanks to Benedikt Daurer (DLS) for sharing this data set for the purpose of this workshop.**\n", "\n", "The data used for this example is from a butterfly scale and has been collected at the I13 instrument at the Diamond Light Source. The raw data has been taken with an array of MediPix3 detectors and their intensities stored in an HDF5 file ```\"dls_i13_butterfly/raw/excalibur_306517_vds.h5\"``` with the following entry\n", "\n", "```bash\n", "\t* data                           shape = (1260, 1793, 2069)\n", "```\n", "\n", "This was a tomographic scan and the scan positions were recorded in a coordinate system that is different from the plane in which the sample was scannend, therefore the positions hat to be converted and were saved in a separate file ```\"dls_i13_butterfly/processing/pos/306517.h5\"``` with the relevant entries for the slow/fast axis of the scanning stage\n", "\n", "```bash\n", "\t* slow                           shape = (1260,)\n", "\t* fast                           shape = (1260,)\n", "```\n", "\n", "There are two main reasons that make this data set a little bit challenging. First, the detector has some missing regions which need to be considered in the reconstruction by providing a binary mask, available ```\"dls_i13_butterfly/processing/masks/excalibur_512x512.h5\"``` \n", "\n", "![](./_assets/i13_mask.png)\n", "\n", "and second, the chosen step size of the scan together with the fact that it follows a \"snake\" trajectory on a rectangular grid makes it prone to grid artefacts. "]}, {"cell_type": "markdown", "id": "91c4ccf4-49c8-437f-b541-2b230f4823b0", "metadata": {}, "source": ["## Loading the data\n", "\n", "We can again used the ```\"Hdf5LoaderFast\"``` for improved file reading performance\n", "\n", "```python\n", "p.scans.scan_00.data = u.Param()\n", "p.scans.scan_00.data.name = 'Hdf5LoaderFast'\n", "p.scans.scan_00.data.orientation = 0\n", "```\n", "\n", "load the intensities\n", "\n", "```python\n", "p.scans.scan_00.data.intensities = u.Param()\n", "p.scans.scan_00.data.intensities.file = path_to_data\n", "p.scans.scan_00.data.intensities.key = \"data\"\n", "```\n", "\n", "and scan positions\n", "\n", "```python\n", "p.scans.scan_00.data.positions = u.Param()\n", "p.scans.scan_00.data.positions.file = path_to_pos\n", "p.scans.scan_00.data.positions.slow_key = \"slow\"\n", "p.scans.scan_00.data.positions.slow_multiplier = 1e-6\n", "p.scans.scan_00.data.positions.fast_key = \"fast\"\n", "p.scans.scan_00.data.positions.fast_multiplier = 1e-6\n", "```\n", "\n", "as well as the mask\n", "\n", "```python\n", "p.scans.scan_00.data.mask = u.Param()\n", "p.scans.scan_00.data.mask.file = path_to_mask\n", "p.scans.scan_00.data.mask.key = \"data\"\n", "```\n", "\n", "and finally provide information (energy, distance, pixel size)\n", "\n", "```python\n", "\n", "p.scans.scan_00.data.distance = 14.65\n", "p.scans.scan_00.data.energy = 9.7\n", "p.scans.scan_00.data.psize = 55e-6\n", "p.scans.scan_00.data.auto_center = False\n", "p.scans.scan_00.data.center = (903.5, 1018.)\n", "p.scans.scan_00.data.shape = (512,512)\n", "```\n", "\n", "and tell the loader to crop a region of shape ```(512,512)``` around the center located at ```(903.5, 1018.)```.\n", "\n"]}, {"cell_type": "markdown", "id": "c1fc3578-2047-41e0-9408-0003adeba7a9", "metadata": {}, "source": ["## Initial probe\n", "\n", "For the initial probe, we can load an already existing probe from a previous reconstruction that was performed during the same experiment with more favourable scan conditions, saved in ```\"dls_i13_butterfly/processing/ptypy/testing/303079_ML_pycuda_1500.ptyr\"``` and looking like this\n", "\n", "![](./_assets/i13_initial_probe.png)"]}, {"cell_type": "markdown", "id": "b114b3a7-eef1-4378-ab49-a5ce79659e6b", "metadata": {}, "source": ["## Reconstruction engine\n", "\n", "As mentioned above, it was found that the SDR algorithm is quite well-suited for this data set, minimising the artefacts that can arise from missing data in the detector and the raster grid pathology. For the engine parameters, we can follow the suggestions from the [SDR paper](https://doi.org/10.1364/OE.27.031246) which suggests $\\sigma=0.5$ and $\\tau=0.1$\n", "\n", "```python\n", "p.engines = u.Param()\n", "p.engines.engine_dr = u.Param()\n", "p.engines.engine_dr.name = \"SDR_pycuda\"\n", "p.engines.engine_dr.numiter = 100\n", "p.engines.engine_dr.numiter_contiguous = 1\n", "p.engines.engine_dr.sigma = 0.5\n", "p.engines.engine_dr.tau = 0.1\n", "p.engines.engine_dr.compute_log_likelihood = True\n", "p.engines.engine_dr.compute_exit_error = False\n", "```\n", "\n", "and after $100$ iterations we get a nice-looking image of a butterfly scale\n", "\n", "![](./_assets/i13_recons_sdr.png)"]}, {"attachments": {}, "cell_type": "markdown", "id": "60339f6e-f92b-4118-9ea3-7daee36cbdf9", "metadata": {}, "source": ["`````{admonition} Exercise \n", ":class: attention\n", "Explore different algorithms such as ePIE, DM, ML, etc. by using code from previous examples and compare against this SDR reconstruction. Which algorithm do you believe worked best for this particular dataset?\n", "`````"]}, {"cell_type": "markdown", "id": "bc8f7e85-7830-406d-813f-89aae9f47459", "metadata": {}, "source": ["---"]}, {"cell_type": "code", "execution_count": null, "id": "ee3cbe0e-7393-4e07-8e6c-a0063eb55dbe", "metadata": {}, "outputs": [], "source": ["import ptypy, os\n", "import ptypy.utils as u\n", "\n", "# This will import the HDF5Loader class\n", "ptypy.load_ptyscan_module(\"hdf5_loader\")\n", "\n", "# This will import the GPU engines\n", "ptypy.load_gpu_engines(\"cuda\")  \n", "\n", "# Root directory of tutorial data\n", "tutorial_data_home = \"../../data/\"\n", "\n", "# Path to HDF5 file with raw data and positions\n", "dataset = \"dls_i13_butterfly/raw/excalibur_306517_vds.h5\"\n", "positions = \"dls_i13_butterfly/processing/pos/306517.h5\"\n", "\n", "# Path to a previous reconstruction\n", "init_probe = \"dls_i13_butterfly/processing/ptypy/testing/303079_ML_pycuda_1500.ptyr\"\n", "\n", "# Path to HDF5 file with mask\n", "mask = \"dls_i13_butterfly/processing/masks/excalibur_512x512.h5\"\n", "\n", "# Absolute paths to HDF5 files with raw data, positions\n", "# initial probe and mask\n", "path_to_data = os.path.join(tutorial_data_home, dataset)\n", "path_to_pos = os.path.join(tutorial_data_home, positions)\n", "path_to_probe = os.path.join(tutorial_data_home, init_probe)\n", "path_to_mask = os.path.join(tutorial_data_home, mask)\n", "\n", "# Create parameter tree\n", "p = u.Param()\n", "\n", "# Set verbose level to info\n", "p.verbose_level = \"interactive\"\n", "\n", "# Scan label\n", "p.run = \"dls_i13_butterfly\"\n", "\n", "# Data loading and processing should \n", "# happen in chunks of this size\n", "p.frames_per_block = 200\n", "\n", "# Set io settings (no files saved)\n", "p.io = u.Param()\n", "p.io.rfile = None\n", "p.io.autosave = u.Param(active=False)\n", "p.io.interaction = u.Param(active=False)\n", "\n", "p.io.autoplot = u.Param()\n", "p.io.autoplot.active = True\n", "p.io.autoplot.threaded = False\n", "p.io.autoplot.layout = \"jupyter\"\n", "p.io.autoplot.interval = 10\n", "\n", "# Define the scan model\n", "p.scans = u.Param()\n", "p.scans.scan_00 = u.Param()\n", "p.scans.scan_00.name = 'BlockFull'\n", "\n", "# Initial illumination (based on previous reconstruction)\n", "p.scans.scan_00.illumination = u.Param()\n", "p.scans.scan_00.illumination.model = \"recon\"\n", "p.scans.scan_00.illumination.recon = u.Param()\n", "p.scans.scan_00.illumination.recon.rfile = path_to_probe\n", "p.scans.scan_00.illumination.photons = None\n", "p.scans.scan_00.illumination.aperture = u.Param()\n", "p.scans.scan_00.illumination.aperture.form = None\n", "p.scans.scan_00.illumination.diversity = u.Param()\n", "p.scans.scan_00.illumination.diversity.power = 0.1\n", "p.scans.scan_00.illumination.diversity.noise = [0.5,1.0]\n", "\n", "# Initial object\n", "p.scans.scan_00.sample = u.Param()\n", "p.scans.scan_00.sample.model = None\n", "p.scans.scan_00.sample.diversity = None\n", "p.scans.scan_00.sample.process = None\n", "\n", "# Coherence parameters (modes)\n", "p.scans.scan_00.coherence = u.Param()\n", "p.scans.scan_00.coherence.num_probe_modes = 1\n", "p.scans.scan_00.coherence.num_object_modes = 1\n", "\n", "# Data loader\n", "p.scans.scan_00.data = u.Param()\n", "p.scans.scan_00.data.name = 'Hdf5LoaderFast'\n", "p.scans.scan_00.data.orientation = 0\n", "\n", "p.scans.scan_00.data.intensities = u.Param()\n", "p.scans.scan_00.data.intensities.file = path_to_data\n", "p.scans.scan_00.data.intensities.key = \"data\"\n", "\n", "p.scans.scan_00.data.positions = u.Param()\n", "p.scans.scan_00.data.positions.file = path_to_pos\n", "p.scans.scan_00.data.positions.slow_key = \"slow\"\n", "p.scans.scan_00.data.positions.slow_multiplier = 1e-6\n", "p.scans.scan_00.data.positions.fast_key = \"fast\"\n", "p.scans.scan_00.data.positions.fast_multiplier = 1e-6\n", "\n", "p.scans.scan_00.data.mask = u.Param()\n", "p.scans.scan_00.data.mask.file = path_to_mask\n", "p.scans.scan_00.data.mask.key = \"data\"\n", "\n", "p.scans.scan_00.data.distance = 14.65\n", "p.scans.scan_00.data.energy = 9.7\n", "p.scans.scan_00.data.psize = 55e-6\n", "p.scans.scan_00.data.auto_center = False\n", "p.scans.scan_00.data.center = (903.5, 1018.)\n", "p.scans.scan_00.data.shape = (512,512)\n", "\n", "# Reconstruct using GPU-accelerated SDR\n", "p.engines = u.Param()\n", "p.engines.engine_dr = u.Param()\n", "p.engines.engine_dr.name = \"SDR_pycuda\"\n", "p.engines.engine_dr.numiter = 100\n", "p.engines.engine_dr.numiter_contiguous = 1\n", "p.engines.engine_dr.sigma = 0.5\n", "p.engines.engine_dr.tau = 0.1\n", "p.engines.engine_dr.compute_log_likelihood = True\n", "p.engines.engine_dr.compute_exit_error = False\n", "\n", "# Run reconstruction\n", "P = ptypy.core.Ptycho(p,level=5)"]}], "metadata": {"kernelspec": {"display_name": "PtyPy", "language": "python", "name": "ptypy_pycuda"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.15"}}, "nbformat": 4, "nbformat_minor": 5}